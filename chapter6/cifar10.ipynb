{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "mlp_concise.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usm-cos-432/InClass/blob/master/chapter6/cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 0,
        "id": "m5DpUPDBx8fL"
      },
      "source": [
        "# CIFAR 10 Lab\n",
        "\n",
        "We explore convolutional model development for the CIFAR 10 data set.\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "Note : When you open a new Colab from Github (like this one), you cannot save changes. So it's usually best to store the Colab in you personal drive \"File > Save a copy in drive...\" before you do anything else."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFazEH-hx8fI"
      },
      "source": [
        "!pip install d2l==0.14.4\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 2,
        "tab": [
          "pytorch"
        ],
        "id": "riKkYRdkx8fL"
      },
      "source": [
        "from d2l import torch as d2l\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils import data\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OBjaEPKzIHa"
      },
      "source": [
        "def load_data_cifar10(batch_size, resize=None): \n",
        "    \"\"\"Download the cifar10 dataset and then load it into memory.\"\"\"\n",
        "    transformer = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    if resize:\n",
        "        transformer.insert(0, transforms.Resize(resize))\n",
        "    \n",
        "    cifar10_train = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transformer)\n",
        "    cifar10_test = torchvision.datasets.CIFAR10(root=\"../data\", train=False, transform=transformer, download=True)\n",
        "    indices = list(range(len(cifar10_train)))\n",
        "    np.random.shuffle(indices)\n",
        "    split = int(np.floor(0.20 * len(cifar10_train)))\n",
        "\n",
        "    cifar10_train_sample = SubsetRandomSampler(indices[split:])\n",
        "    cifar10_valid_sample = SubsetRandomSampler(indices[:split])\n",
        "\n",
        "\n",
        "    return (data.DataLoader(cifar10_train, batch_size, sampler=cifar10_train_sample),\n",
        "            data.DataLoader(cifar10_train, batch_size, sampler=cifar10_valid_sample),\n",
        "            data.DataLoader(cifar10_test, batch_size, shuffle=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tgV_W_Q5Kmi"
      },
      "source": [
        "def get_cifar10_labels(labels):  \n",
        "    \"\"\"Return text labels for the CIFAR10 dataset.\"\"\"\n",
        "    text_labels = ['plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "    return [text_labels[int(i)] for i in labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkxvXo_L4VYG"
      },
      "source": [
        "# modified show_images to unnormalize tensors and move RGB channels to beginning\n",
        "def show_images(imgs, num_rows, num_cols, titles=None, scale=2.5):  #@save\n",
        "    \"\"\"Plot a list of images.\"\"\"\n",
        "    figsize = (num_cols * scale, num_rows * scale)\n",
        "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
        "    axes = axes.flatten()\n",
        "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
        "        img = img / 2 + 0.5     # unnormalize\n",
        "        npimg = img.numpy()\n",
        "        npimg = np.transpose(npimg,(1,2,0)) \n",
        "        ax.imshow(npimg)\n",
        "        ax.axes.get_xaxis().set_visible(False)\n",
        "        ax.axes.get_yaxis().set_visible(False)\n",
        "        if titles:\n",
        "            ax.set_title(titles[i])\n",
        "    return axes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJei9CPF-qIk"
      },
      "source": [
        "batch_size=24\n",
        "\n",
        "train_iter, valid_iter, test_iter = load_data_cifar10(batch_size)\n",
        "X, y = next(iter(train_iter))\n",
        "\n",
        "show_images(X, 2, 9, titles=get_cifar10_labels(y));\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSYndkh35zrK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYw78zYt3Zq7"
      },
      "source": [
        "print(X.shape)\n",
        "print(len(train_iter.sampler))\n",
        "print(len(valid_iter.sampler))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 4,
        "id": "WOqykrrPx8fO"
      },
      "source": [
        "## Model\n",
        "\n",
        "As compared with our concise implementation\n",
        "of softmax regression implementation\n",
        "(:numref:`sec_softmax_concise`),\n",
        "the only difference is that we add\n",
        "*two* fully-connected layers\n",
        "(previously, we added *one*).\n",
        "The first is our hidden layer,\n",
        "which contains 256 hidden units\n",
        "and applies the ReLU activation function.\n",
        "The second is our output layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym6tPWWh-Yid"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(in_features=16 * 5 * 5, out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 8,
        "id": "AofUKPMZx8fR"
      },
      "source": [
        "The training loop is exactly the same\n",
        "as when we implemented softmax regression.\n",
        "This modularity enables us to separate\n",
        "matters concerning the model architecture\n",
        "from orthogonal considerations. \n",
        "\n",
        "train_ch6 code was changed to include train loss & train accuracy in plot\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqB0B5uDADhj"
      },
      "source": [
        "def train_ch6(net, train_iter, test_iter, num_epochs, lr,\n",
        "              device=d2l.try_gpu()):\n",
        "    \"\"\"Train a model with a GPU (defined in Chapter 6).\"\"\"\n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "            torch.nn.init.xavier_uniform_(m.weight)\n",
        "    net.apply(init_weights)\n",
        "    print('training on', device)\n",
        "    net.to(device)\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    animator = d2l.Animator(xlabel='epoch', xlim=[0, num_epochs],\n",
        "                            # ylim=[0.0, 3.0],\n",
        "                            legend=['train loss', 'train acc', 'test acc'])\n",
        "    timer = d2l.Timer()\n",
        "    for epoch in range(num_epochs):\n",
        "        # Sum of training loss, sum of training accuracy, no. of examples\n",
        "        metric = d2l.Accumulator(3)\n",
        "        for i, (X, y) in enumerate(train_iter):\n",
        "            timer.start()\n",
        "            net.train()\n",
        "            optimizer.zero_grad()\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y)\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "            with torch.no_grad():\n",
        "                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
        "            timer.stop()\n",
        "            train_loss = metric[0]/metric[2]\n",
        "            train_acc = metric[1]/metric[2]\n",
        "            if (i + 1) % 50 == 0:\n",
        "                animator.add(epoch + i / len(train_iter),\n",
        "                             (train_loss, train_acc, None))\n",
        "        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter, device)\n",
        "        animator.add(epoch+1, (train_loss, train_acc, test_acc))\n",
        "    print(f'loss {train_loss:.3f}, train acc {train_acc:.3f}, '\n",
        "          f'test acc {test_acc:.3f}')\n",
        "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
        "          f'on {str(device)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 10,
        "tab": [
          "pytorch"
        ],
        "id": "Sd8xzafqx8fR"
      },
      "source": [
        "batch_size, lr, num_epochs = 256, 0.1, 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 12,
        "tab": [
          "pytorch"
        ],
        "id": "t72KPDHmx8fU"
      },
      "source": [
        "train_iter, valid_iter, test_iter = load_data_cifar10(batch_size)\n",
        "\n",
        "train_ch6(net, train_iter, valid_iter, num_epochs, lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP8MDxep7TM7"
      },
      "source": [
        "print(d2l.evaluate_accuracy_gpu(net, train_iter))\n",
        "print(d2l.evaluate_accuracy_gpu(net, test_iter))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkypVUSsHROc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jcD5CYzPWW3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}