{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "mlp_concise.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usm-cos-432/InClass/blob/master/chapter4/mlp_concise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnZKQL93x8fH",
        "colab_type": "text"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFazEH-hx8fI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install d2l==0.14.4\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 0,
        "id": "m5DpUPDBx8fL",
        "colab_type": "text"
      },
      "source": [
        "# Concise Implementation of Multilayer Perceptrons\n",
        ":label:`sec_mlp_concise`\n",
        "\n",
        "As you might expect, by relying on the high-level APIs,\n",
        "we can implement MLPs even more concisely.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 2,
        "tab": [
          "pytorch"
        ],
        "id": "riKkYRdkx8fL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from d2l import torch as d2l\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils import data\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OBjaEPKzIHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data_fashion_mnist(batch_size, resize=None): \n",
        "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\"\"\"\n",
        "    trans = [transforms.ToTensor()]\n",
        "    if resize:\n",
        "        trans.insert(0, transforms.Resize(resize))\n",
        "    trans = transforms.Compose(trans)\n",
        "    mnist_train = torchvision.datasets.FashionMNIST(root=\"../data\", train=True, transform=trans, download=True)\n",
        "    mnist_test = torchvision.datasets.FashionMNIST(root=\"../data\", train=False, transform=trans, download=True)\n",
        "    indices = list(range(len(mnist_train)))\n",
        "    np.random.shuffle(indices)\n",
        "    split = int(np.floor(0.20 * len(mnist_train)))\n",
        "    mnist_train_sample = SubsetRandomSampler(indices[split:])\n",
        "    mnist_valid_sample = SubsetRandomSampler(indices[:split])\n",
        "\n",
        "    return (data.DataLoader(mnist_train, batch_size, sampler=mnist_train_sample),\n",
        "            data.DataLoader(mnist_train, batch_size, sampler=mnist_valid_sample),\n",
        "            data.DataLoader(mnist_test, batch_size, shuffle=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8olxm9pk5mlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater): \n",
        "    \"\"\"Train a model (defined in Chapter 3).\"\"\"\n",
        "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.0, 1.0],\n",
        "                        legend=['train loss', 'train acc', 'test acc'])\n",
        "    for epoch in range(num_epochs):\n",
        "        train_metrics = d2l.train_epoch_ch3(net, train_iter, loss, updater)\n",
        "        test_acc = d2l.evaluate_accuracy(net, test_iter)\n",
        "        animator.add(epoch + 1, train_metrics + (test_acc,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJei9CPF-qIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 24\n",
        "train_iter, valid_iter, test_iter = load_data_fashion_mnist(batch_size)\n",
        "X, y = next(iter(train_iter))\n",
        "d2l.show_images(X.reshape(batch_size, 28, 28), 2, 9, titles=d2l.get_fashion_mnist_labels(y));\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 4,
        "id": "WOqykrrPx8fO",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "\n",
        "As compared with our concise implementation\n",
        "of softmax regression implementation\n",
        "(:numref:`sec_softmax_concise`),\n",
        "the only difference is that we add\n",
        "*two* fully-connected layers\n",
        "(previously, we added *one*).\n",
        "The first is our hidden layer,\n",
        "which contains 256 hidden units\n",
        "and applies the ReLU activation function.\n",
        "The second is our output layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym6tPWWh-Yid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = nn.Sequential(nn.Flatten(),\n",
        "                    nn.Linear(784, 256),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(256, 10))\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.normal_(m.weight, std=0.01)\n",
        "\n",
        "net.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 8,
        "id": "AofUKPMZx8fR",
        "colab_type": "text"
      },
      "source": [
        "The training loop is exactly the same\n",
        "as when we implemented softmax regression.\n",
        "This modularity enables us to separate\n",
        "matters concerning the model architecture\n",
        "from orthogonal considerations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 10,
        "tab": [
          "pytorch"
        ],
        "id": "Sd8xzafqx8fR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size, lr, num_epochs = 256, 0.1, 10\n",
        "loss = nn.CrossEntropyLoss()\n",
        "trainer = torch.optim.SGD(net.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 12,
        "tab": [
          "pytorch"
        ],
        "id": "t72KPDHmx8fU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iter, valid_iter, test_iter = load_data_fashion_mnist(batch_size)\n",
        "net.apply(init_weights)\n",
        "train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP8MDxep7TM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(d2l.evaluate_accuracy(net, train_iter))\n",
        "print(d2l.evaluate_accuracy(net, test_iter))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}